{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d3194cd",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "I was wrong. Generation of word pairs ignore the condition that the inner masks are symmetric. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d71a3a3",
   "metadata": {},
   "source": [
    "## todo\n",
    "- relax punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0cf4d9",
   "metadata": {},
   "source": [
    "From https://czechtheworld.com/best-palindromes/#palindromes-symmetric-by-words\n",
    "\n",
    "- You can cage a swallow, can’t you, but you can’t swallow a cage, can you?\n",
    "- Fall leaves as soon as leaves fall.\n",
    "- King, are you glad you are king?\n",
    "- So patient a nurse to nurse a patient so.\n",
    "- First ladies rule the state, and state the rule: “Ladies First!”\n",
    "- Do I, like, look like I do?\n",
    "- Sorry, I am very awkward. Very am I sorry.\n",
    "- Is it crazy how saying sentences backwards creates backwards sentences saying how crazy it is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dd6f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "import numpy as np\n",
    "import scipy\n",
    "from transformers import AutoTokenizer, BertForMaskedLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822c68bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uncasedTok = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "casedTok = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "uncasedBert = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "casedBert = BertForMaskedLM.from_pretrained(\"bert-base-cased\")\n",
    "CASED = 'CASED'\n",
    "UNCASED = 'UNCASED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9656bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMode(logits):\n",
    "    return logits[0].argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2cf6f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend(casing, response_len, prompt, ends_with):\n",
    "    if casing is CASED:\n",
    "        bert = casedBert\n",
    "        tok = casedTok\n",
    "    else:\n",
    "        bert = uncasedBert\n",
    "        tok = uncasedTok\n",
    "    input_idx = tok.encode(prompt.strip(' '))\n",
    "    assert input_idx[-1] == tok.sep_token_id\n",
    "    input_idx.pop(-1)\n",
    "    len_input = len(input_idx)\n",
    "    input_idx += (\n",
    "        [tok.mask_token_id] * response_len + \n",
    "        [tok.convert_tokens_to_ids(ends_with)] + \n",
    "        [tok.sep_token_id]\n",
    "    )\n",
    "    print(tok.decode(input_idx))\n",
    "    buffer = input_idx[:]\n",
    "    \n",
    "    for i in range(response_len):\n",
    "        logits = bert(torch.tensor([buffer]))[0]\n",
    "        prediction = getMode(logits)\n",
    "        buffer[len_input + i] = prediction[len_input + i]\n",
    "#         print(i, tok.decode(buffer))\n",
    "    print()\n",
    "    print(tok.decode(buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "077c51fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] nobody expected the cancellation of the flight, so people began to panic. what if the representatives cannot make it in time? [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]? [SEP]\n",
      "\n",
      "[CLS] nobody expected the cancellation of the flight, so people began to panic. what if the representatives cannot make it in time? how long is it going to take? and how long will it take to arrive? [SEP]\n",
      "\n",
      "[CLS] nobody expected the cancellation of the flight, so people began to panic. what if the representatives cannot make it in time? [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]. [SEP]\n",
      "\n",
      "[CLS] nobody expected the cancellation of the flight, so people began to panic. what if the representatives cannot make it in time? \" asked the american. \" yes, \" he replied, \" it will not. [SEP]\n",
      "\n",
      "[CLS] Nobody expected the cancellation of the flight, so people began to panic. What if the representatives cannot make it in time? [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]? [SEP]\n",
      "\n",
      "[CLS] Nobody expected the cancellation of the flight, so people began to panic. What if the representatives cannot make it in time? \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" What? [SEP]\n",
      "\n",
      "[CLS] Nobody expected the cancellation of the flight, so people began to panic. What if the representatives cannot make it in time? [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]. [SEP]\n",
      "\n",
      "[CLS] Nobody expected the cancellation of the flight, so people began to panic. What if the representatives cannot make it in time? \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \". [SEP]\n"
     ]
    }
   ],
   "source": [
    "extend(UNCASED, 16, 'Nobody expected the cancellation of the flight, so people began to panic. What if the representatives cannot make it in time?', '?')\n",
    "print()\n",
    "extend(UNCASED, 16, 'Nobody expected the cancellation of the flight, so people began to panic. What if the representatives cannot make it in time?', '.')\n",
    "print()\n",
    "extend(CASED, 16, 'Nobody expected the cancellation of the flight, so people began to panic. What if the representatives cannot make it in time?', '?')\n",
    "print()\n",
    "extend(CASED, 16, 'Nobody expected the cancellation of the flight, so people began to panic. What if the representatives cannot make it in time?', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a96ee40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]? [SEP]\n",
      "\n",
      "[CLS] \" what the hell are you doing, \" he said, \" getting a gun? [SEP]\n"
     ]
    }
   ],
   "source": [
    "extend(UNCASED, 16, '', '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31a14335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] In reality, my dog [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]. [SEP]\n",
      "\n",
      "[CLS] In reality, my dog is the only - the - best - thing that could ever be in my life. [SEP]\n"
     ]
    }
   ],
   "source": [
    "extend(CASED, 16, 'In reality, my dog', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eefd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def proposeReversal(prompt):\n",
    "#     words = [*reversed(prompt.split(' '))]\n",
    "#     return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "82c777fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crab(response_len, prompt, ends_with, sampleMethod, casing, seed=None):\n",
    "    if casing is CASED:\n",
    "        bert = casedBert\n",
    "        tok = casedTok\n",
    "    else:\n",
    "        bert = uncasedBert\n",
    "        tok = uncasedTok\n",
    "    input_idx = tok.encode(prompt.strip(' '))[1:-1]\n",
    "    buffer = [None] * (\n",
    "        1 + len(input_idx) + response_len + len(input_idx) + 1 + 1\n",
    "    )\n",
    "    acc = 0\n",
    "    buffer[acc] = tok.cls_token_id\n",
    "    acc += 1\n",
    "    buffer[acc : acc + len(input_idx)] = input_idx\n",
    "    acc += len(input_idx)\n",
    "    buffer[acc : acc + response_len] = [tok.mask_token_id] * response_len\n",
    "    acc += response_len\n",
    "    buffer[acc : acc + len(input_idx)] = reversed(input_idx)\n",
    "    acc += len(input_idx)\n",
    "    if ends_with:\n",
    "        buffer[acc] = tok.convert_tokens_to_ids(ends_with)\n",
    "        acc += 1\n",
    "    else:\n",
    "        buffer.pop(-1)\n",
    "    buffer[acc] = tok.sep_token_id\n",
    "    acc += 1\n",
    "    assert acc == len(buffer)\n",
    "    \n",
    "    print(tok.decode(buffer))\n",
    "    for i in range((response_len + 1) // 2):\n",
    "#         print(i, tok.decode(buffer))\n",
    "        left  = 1 + len(input_idx) + i\n",
    "        right = 1 + len(input_idx) + response_len - i - 1\n",
    "        if seed is not None:\n",
    "            pick = seed[i]\n",
    "        else:\n",
    "            pick = 0\n",
    "        word_id = sampleMethod(buffer, left, right, pick, bert, tok)\n",
    "        buffer[left] = word_id\n",
    "        buffer[right] = word_id\n",
    "#     print()\n",
    "    print(tok.decode(buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e9b64bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastest(buffer, left, right, _, bert, tok):\n",
    "    logits = bert(torch.tensor([buffer]))[0].detach()\n",
    "    logit = (\n",
    "        scipy.special.softmax(logits[0][left]) * \n",
    "        scipy.special.softmax(logits[0][right])\n",
    "    )\n",
    "    return logit.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b727e46f",
   "metadata": {},
   "source": [
    "Optimization: stop looking when left prob < current best shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "32ec85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slowest(buffer, left, right, pick, bert, tok):\n",
    "    logits = bert(torch.tensor([buffer]))[0].detach()\n",
    "    left_probs = scipy.special.softmax(logits[0][left])\n",
    "    left_rank = np.argsort(left_probs)\n",
    "    probs = []\n",
    "    max_prob = [0]\n",
    "    last_print = None\n",
    "    for i, word_id in enumerate(reversed(left_rank)):\n",
    "#         print(i)\n",
    "        left_prob = left_probs[word_id]\n",
    "#         print(left_prob)\n",
    "        if left_prob < max_prob[-1]:\n",
    "            print('\\n  Early stopping at', i, 'which is', i / len(left_probs))\n",
    "            break\n",
    "        buffer[left] = word_id\n",
    "        logits = bert(torch.tensor([buffer]))[0].detach()\n",
    "        right_probs = scipy.special.softmax(logits[0][right])\n",
    "        prob = left_prob * right_probs[word_id]\n",
    "#         print('*', right_probs[word_id], '=', prob)\n",
    "        probs.append((word_id, prob))\n",
    "        probs.sort(key=lambda x:x[1])\n",
    "        max_prob.append(prob)\n",
    "        max_prob.sort(reverse = True)\n",
    "        max_prob = max_prob[:pick + 1]\n",
    "        if last_print != max_prob[0]:\n",
    "            last_print = max_prob[0]\n",
    "            print(\n",
    "                '  Current best: \"', tok.convert_ids_to_tokens(\n",
    "                    probs[-1]\n",
    "                )[0], '\"...', end = '\\r', flush = True, \n",
    "            )\n",
    "    s = sorted(probs, key=lambda x:x[1])\n",
    "    return s[-1 - pick][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0b37e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAIL_CUT = 0\n",
    "# def slowestRand(buffer, left, right):\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fc0efe77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] fall leaves as [MASK] as leaves fall. [SEP]\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "[CLS] fall leaves as soon as leaves fall. [SEP]\n",
      "\n",
      "[CLS] Fall leaves as [MASK] as leaves Fall. [SEP]\n",
      "  Early stopping at 4 which is 0.00013795006207752792\n",
      "[CLS] Fall leaves as easily as leaves Fall. [SEP]\n"
     ]
    }
   ],
   "source": [
    "crab(1, 'Fall leaves as', '.', slowest, UNCASED)\n",
    "print()\n",
    "crab(1, 'Fall leaves as', '.', slowest, CASED, [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7815ff63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] fall leaves [MASK] [MASK] [MASK] leaves fall. [SEP]\n",
      "  Early stopping at 30 which is 0.000982897582071948\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "[CLS] fall leaves falling. falling leaves fall. [SEP]\n"
     ]
    }
   ],
   "source": [
    "crab(3, 'Fall leaves', '.', slowest, UNCASED, [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "11d42836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] fall [MASK] [MASK] [MASK] [MASK] [MASK] fall. [SEP]\n",
      "  Early stopping at 20 which is 0.0006552650547146321\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "[CLS] fall = fall. fall = fall. [SEP]\n"
     ]
    }
   ],
   "source": [
    "crab(5, 'Fall', '.', slowest, UNCASED, [5, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c4d599a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] so patient a nurse [MASK] nurse a patient so. [SEP]\n",
      "  Early stopping at 6 which is 0.00019657951641438963\n",
      "[CLS] so patient a nurse to nurse a patient so. [SEP]\n"
     ]
    }
   ],
   "source": [
    "crab(1, 'So patient a nurse', '.', slowest, UNCASED, [5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7f609e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] so patient a [MASK] [MASK] [MASK] a patient so. [SEP]\n",
      "  Early stopping at 25 which is 0.0008190813183932901\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "[CLS] so patient a doctor a doctor a patient so. [SEP]\n"
     ]
    }
   ],
   "source": [
    "crab(3, 'So patient a', '.', slowest, UNCASED, [2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "751bffc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] is it crazy how saying sentences backwards [MASK] backwards sentences saying how crazy it is? [SEP]\n",
      "  Early stopping at 10 which is 0.00032763252735731603\n",
      "[CLS] is it crazy how saying sentences backwards makes backwards sentences saying how crazy it is? [SEP]\n"
     ]
    }
   ],
   "source": [
    "crab(\n",
    "    1, 'Is it crazy how saying sentences backwards', '?', slowest, \n",
    "    UNCASED, [9], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ac9cef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crab(\n",
    "#     3, 'Is it crazy how saying sentences', '?', slowest, \n",
    "#     UNCASED, [0, 9-9], \n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c80f57",
   "metadata": {},
   "source": [
    "Junyan recommendation: outfilling\n",
    "## Outfilling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2b6c8d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outfill(response_len, prompt, ends_with, sampleMethod, casing, seed=None):\n",
    "    if casing is CASED:\n",
    "        bert = casedBert\n",
    "        tok = casedTok\n",
    "    else:\n",
    "        bert = uncasedBert\n",
    "        tok = uncasedTok\n",
    "    input_idx = tok.encode(prompt.strip(' '))[1:-1]\n",
    "    buffer = [None] * (\n",
    "        1 + response_len + len(input_idx) + response_len + 1 + 1\n",
    "    )\n",
    "    acc = 0\n",
    "    buffer[acc] = tok.cls_token_id\n",
    "    acc += 1\n",
    "    buffer[acc : acc + response_len] = [tok.mask_token_id] * response_len\n",
    "    acc += response_len\n",
    "    buffer[acc : acc + len(input_idx)] = input_idx\n",
    "    acc += len(input_idx)\n",
    "    buffer[acc : acc + response_len] = [tok.mask_token_id] * response_len\n",
    "    acc += response_len\n",
    "    if ends_with:\n",
    "        buffer[acc] = tok.convert_tokens_to_ids(ends_with)\n",
    "        acc += 1\n",
    "    else:\n",
    "        buffer.pop(-1)\n",
    "    buffer[acc] = tok.sep_token_id\n",
    "    acc += 1\n",
    "    assert acc == len(buffer)\n",
    "    \n",
    "    print(tok.decode(buffer))\n",
    "    for i in range(response_len):\n",
    "#         print(i, tok.decode(buffer))\n",
    "        left  = 1 + response_len - i - 1\n",
    "        right = 1 + response_len + len(input_idx) + i\n",
    "        if seed is not None:\n",
    "            pick = seed[i]\n",
    "        else:\n",
    "            pick = 0\n",
    "        word_id = sampleMethod(buffer, left, right, pick, bert, tok)\n",
    "        buffer[left] = word_id\n",
    "        buffer[right] = word_id\n",
    "#     print()\n",
    "    print(tok.decode(buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d689e26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] leaves as soon as leaves [MASK]. [SEP]\n",
      "  Early stopping at 70 which is 0.0022934276915012124\n",
      "[CLS] he leaves as soon as leaves he. [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(1, 'leaves as soon as leaves', '.', slowest, UNCASED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eb8b480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] as soon as [MASK] [MASK]. [SEP]\n",
      "[CLS] i said as soon as said i. [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(2, 'as soon as', '.', fastest, UNCASED)\n",
    "# slowest never returned..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c322c760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] [MASK] soon [MASK] [MASK] [MASK]. [SEP]\n",
      "  Early stopping at 24 which is 0.0007863180656575585\n",
      "  Early stopping at 26 which is 0.0008518445711290217\n",
      "  Early stopping at 41 which is 0.0013432933621649957\n",
      "[CLS] someday maybe, soon, maybe someday. [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(3, 'soon', '.', slowest, UNCASED, [0, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa8a1928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] patient a nurse to nurse a patient [MASK]. [SEP]\n",
      "  Early stopping at 162 which is 0.0053076469431885195\n",
      "[CLS] pet patient a nurse to nurse a patient pet. [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    1, 'patient a nurse to nurse a patient', '.', \n",
    "    slowest, UNCASED, [5], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e07af57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] a nurse to nurse a [MASK] [MASK]. [SEP]\n",
      "[CLS] someone needs a nurse to nurse a needs someone. [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    2, 'a nurse to nurse a', '.', \n",
    "    fastest, UNCASED, [0, 0], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41c7c3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] [MASK] [MASK] to [MASK] [MASK] [MASK] [MASK]. [SEP]\n",
      "  Early stopping at 484 which is 0.015857414324094096\n",
      "  Early stopping at 73 which is 0.002391717449708407\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "  Early stopping at 7 which is 0.00022934276915012123\n",
      "[CLS] baby, you have to have you, baby. [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    4, 'to', '.', \n",
    "    slowest, UNCASED, [1, 0, 0, 0], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03af8a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] it crazy how saying sentences backwards creates backwards sentences saying how crazy it [MASK]? [SEP]\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "[CLS] is it crazy how saying sentences backwards creates backwards sentences saying how crazy it is? [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    1, 'it crazy how saying sentences backwards creates backwards sentences saying how crazy it', \n",
    "    '?', \n",
    "    slowest, UNCASED, [0], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "308acd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] crazy how saying sentences backwards creates backwards sentences saying how crazy [MASK] [MASK]? [SEP]\n",
      "  Early stopping at 141 which is 0.004619618635738156\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "[CLS] are you crazy how saying sentences backwards creates backwards sentences saying how crazy you are? [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    2, 'crazy how saying sentences backwards creates backwards sentences saying how crazy', \n",
    "    '?', \n",
    "    slowest, UNCASED, [1, 0], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae706877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] crazy how saying sentences backwards creates backwards sentences saying how crazy [MASK] [MASK]? [SEP]\n",
      "  Early stopping at 2 which is 6.552650547146321e-05\n",
      "  Early stopping at 2 which is 6.552650547146321e-05\n",
      "[CLS] it is crazy how saying sentences backwards creates backwards sentences saying how crazy is it? [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    2, 'crazy how saying sentences backwards creates backwards sentences saying how crazy', \n",
    "    '?', \n",
    "    slowest, UNCASED, [2, 0], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e077324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] crazy how saying sentences backwards creates backwards sentences saying how crazy [MASK] [MASK]? [SEP]\n",
      "  Early stopping at 163 which is 0.005340410195924251\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "[CLS] words are crazy how saying sentences backwards creates backwards sentences saying how crazy are words? [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    2, 'crazy how saying sentences backwards creates backwards sentences saying how crazy', \n",
    "    '?', \n",
    "    slowest, UNCASED, [4, 0], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9c25d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] [MASK] how saying sentences backwards creates backwards sentences saying how [MASK] [MASK] [MASK]? [SEP]\n",
      "[CLS] so how about how saying sentences backwards creates backwards sentences saying how about how so? [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    3, 'how saying sentences backwards creates backwards sentences saying how', \n",
    "    '?', \n",
    "    fastest, UNCASED, [0, 0, 0], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0224a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] [MASK] [MASK] saying sentences backwards creates backwards sentences saying [MASK] [MASK] [MASK] [MASK]? [SEP]\n",
      "[CLS] backwards sentences saying sentences saying sentences backwards creates backwards sentences saying sentences saying sentences backwards? [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    4, 'saying sentences backwards creates backwards sentences saying', \n",
    "    '?', \n",
    "    fastest, UNCASED, [0, 0, 0, 0], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92e09710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] [MASK] [MASK] saying sentences backwards creates backwards sentences saying [MASK] [MASK] [MASK] [MASK]? [SEP]\n",
      "  Early stopping at 29 which is 0.0009501343293362165\n",
      "  Early stopping at 14 which is 0.00045868553830024245\n",
      "  Early stopping at 15 which is 0.000491448791035974\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "[CLS] \" hello \", saying sentences backwards creates backwards sentences saying, \" hello \"? [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    4, 'saying sentences backwards creates backwards sentences saying', \n",
    "    '?', \n",
    "    slowest, UNCASED, [2, 0, 3, 0], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "989529bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] [MASK] [MASK] [MASK] sentences backwards creates backwards sentences [MASK] [MASK] [MASK] [MASK] [MASK]? [SEP]\n",
      "  Early stopping at 26 which is 0.0008518445711290217\n",
      "  Early stopping at 4 which is 0.00013105301094292642\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "[CLS] backwards creates backwards sentences. sentences backwards creates backwards sentences. sentences backwards creates backwards? [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    5, 'sentences backwards creates backwards sentences', \n",
    "    '?', \n",
    "    slowest, UNCASED, [0, 0, 0, 0, 0], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e88b0613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] [MASK] [MASK] [MASK] sentences backwards creates backwards sentences [MASK] [MASK] [MASK] [MASK] [MASK]? [SEP]\n",
      "  Early stopping at 26 which is 0.0008518445711290217\n",
      "  Early stopping at 35 which is 0.0011467138457506062\n",
      "  Early stopping at 21 which is 0.0006880283074503637\n",
      "  Early stopping at 2 which is 6.552650547146321e-05\n",
      "  Early stopping at 6 which is 0.00019657951641438963\n",
      "[CLS] backwards words are words. sentences backwards creates backwards sentences. words are words backwards? [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    5, 'sentences backwards creates backwards sentences', \n",
    "    '?', \n",
    "    slowest, UNCASED, [0, 2, 0, 0, 0], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1b046fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] creates [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]? [SEP]\n",
      "  Early stopping at 54 which is 0.0017692156477295065\n",
      "  Early stopping at 703 which is 0.023032566673219318\n",
      "  Early stopping at 8 which is 0.00026210602188585284\n",
      "  Early stopping at 14 which is 0.00045868553830024245\n",
      "  Early stopping at 15 which is 0.000491448791035974\n",
      "  Early stopping at 29 which is 0.0009501343293362165\n",
      "  Early stopping at 3 which is 9.828975820719482e-05\n",
      "[CLS] what is what is that thing that creates that thing that is what is what? [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    7, 'creates', \n",
    "    '?', \n",
    "    slowest, UNCASED, [2, 0, 0, 0, 0, 0, 0], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ad4a21a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] [MASK] [MASK] [MASK] creates [MASK] [MASK] [MASK] [MASK] [MASK]? [SEP]\n",
      "  Early stopping at 110 which is 0.0036039578009304765\n",
      "  Early stopping at 63 which is 0.0020640849223510912\n",
      "  Early stopping at 8 which is 0.00026210602188585284\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "  Early stopping at 6 which is 0.00019657951641438963\n",
      "[CLS] what is that thing that creates that thing that is what? [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    5, 'creates', \n",
    "    '?', \n",
    "    slowest, UNCASED, [3, 0, 1, 0, 0, 0, 0], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "848ece38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] [MASK] [MASK] means [MASK] [MASK] [MASK] [MASK]. [SEP]\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "  Early stopping at 5 which is 0.00016381626367865801\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "  Early stopping at 38 which is 0.0012450036039578008\n",
      "[CLS] letter \" a \" means \" a \" letter. [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    4, 'means', \n",
    "    '.', \n",
    "    slowest, UNCASED, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cf9da8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] [MASK] [MASK] [MASK] means [MASK] [MASK] [MASK] [MASK] [MASK]. [SEP]\n",
      "  Early stopping at 2 which is 6.552650547146321e-05\n",
      "  Early stopping at 8 which is 0.00026210602188585284\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "  Early stopping at 9 which is 0.00029486927462158444\n",
      "  Early stopping at 312 which is 0.01022213485354826\n",
      "[CLS] ending in \" a \" means \" a \" in ending. [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    5, 'means', \n",
    "    '.', \n",
    "    slowest, UNCASED, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4414c7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] [MASK] only [MASK] [MASK] [MASK]. [SEP]\n",
      "  Early stopping at 113 which is 0.003702247559137671\n",
      "  Early stopping at 40 which is 0.0013105301094292641\n",
      "  Early stopping at 326 which is 0.010680820391848502\n",
      "[CLS] division one had only had one division. [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    3, 'only', \n",
    "    '.', \n",
    "    slowest, UNCASED, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0feb35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slowestNoPunc(buffer, left, right, pick, bert, tok):\n",
    "    logits = bert(torch.tensor([buffer]))[0].detach()\n",
    "    left_probs = scipy.special.softmax(logits[0][left])\n",
    "    left_rank = np.argsort(left_probs)\n",
    "    probs = []\n",
    "    max_prob = [0]\n",
    "    last_print = None\n",
    "    for i, word_id in enumerate(reversed(left_rank)):\n",
    "#         print(i)\n",
    "        if not tok.convert_ids_to_tokens([word_id])[0].isalpha():\n",
    "            continue\n",
    "        left_prob = left_probs[word_id]\n",
    "#         print(left_prob)\n",
    "        if left_prob < max_prob[-1]:\n",
    "            print('\\n  Early stopping at', i, 'which is', i / len(left_probs))\n",
    "            break\n",
    "        buffer[left] = word_id\n",
    "        logits = bert(torch.tensor([buffer]))[0].detach()\n",
    "        right_probs = scipy.special.softmax(logits[0][right])\n",
    "        prob = left_prob * right_probs[word_id]\n",
    "#         print('*', right_probs[word_id], '=', prob)\n",
    "        probs.append((word_id, prob))\n",
    "        probs.sort(key=lambda x:x[1])\n",
    "        max_prob.append(prob)\n",
    "        max_prob.sort(reverse = True)\n",
    "        max_prob = max_prob[:pick + 1]\n",
    "        if last_print != max_prob[0]:\n",
    "            last_print = max_prob[0]\n",
    "            print(\n",
    "                '  Current best: \"', tok.convert_ids_to_tokens(\n",
    "                    probs[-1]\n",
    "                )[0], '\"...', end = '\\r', flush = True, \n",
    "            )\n",
    "    s = sorted(probs, key=lambda x:x[1])\n",
    "    return s[-1 - pick][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "fa6b490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] [MASK] [MASK] [MASK] but [MASK] [MASK] [MASK] [MASK] [MASK]. [SEP]\n",
      "  Current best: \" it \"....\n",
      "  Early stopping at 77 which is 0.0025227704606513336\n",
      "  Current best: \" felt \"...\n",
      "  Early stopping at 166 which is 0.0054386999541314466\n",
      "  Current best: \" i \"...\n",
      "  Early stopping at 58 which is 0.001900268658672433\n",
      "  Current best: \" was \".......\n",
      "  Early stopping at 14 which is 0.00045868553830024245\n",
      "  Current best: \" it \".....\n",
      "  Early stopping at 12 which is 0.00039315903282877927\n",
      "[CLS] it was i felt it but it felt i was it. [SEP]\n"
     ]
    }
   ],
   "source": [
    "outfill(\n",
    "    5, 'but', \n",
    "    '.', \n",
    "    slowestNoPunc, UNCASED, \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
