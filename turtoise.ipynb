{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d3194cd",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "I was wrong. Generation of word pairs ignore the condition that the inner masks are symmetric. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d71a3a3",
   "metadata": {},
   "source": [
    "## todo\n",
    "- relax punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0cf4d9",
   "metadata": {},
   "source": [
    "From https://czechtheworld.com/best-palindromes/#palindromes-symmetric-by-words\n",
    "\n",
    "- You can cage a swallow, can’t you, but you can’t swallow a cage, can you?\n",
    "- Fall leaves as soon as leaves fall.\n",
    "- King, are you glad you are king?\n",
    "- So patient a nurse to nurse a patient so.\n",
    "- First ladies rule the state, and state the rule: “Ladies First!”\n",
    "- Do I, like, look like I do?\n",
    "- Sorry, I am very awkward. Very am I sorry.\n",
    "- Is it crazy how saying sentences backwards creates backwards sentences saying how crazy it is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dd6f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "import numpy as np\n",
    "import scipy\n",
    "from transformers import AutoTokenizer, BertForMaskedLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822c68bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uncasedTok = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "casedTok = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "uncasedBert = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "casedBert = BertForMaskedLM.from_pretrained(\"bert-base-cased\")\n",
    "CASED = 'CASED'\n",
    "UNCASED = 'UNCASED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9656bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMode(logits):\n",
    "    return logits[0].argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2cf6f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend(casing, response_len, prompt, ends_with):\n",
    "    if casing is CASED:\n",
    "        bert = casedBert\n",
    "        tok = casedTok\n",
    "    else:\n",
    "        bert = uncasedBert\n",
    "        tok = uncasedTok\n",
    "    input_idx = tok.encode(prompt.strip(' '))\n",
    "    assert input_idx[-1] == tok.sep_token_id\n",
    "    input_idx.pop(-1)\n",
    "    len_input = len(input_idx)\n",
    "    input_idx += (\n",
    "        [tok.mask_token_id] * response_len + \n",
    "        [tok.convert_tokens_to_ids(ends_with)] + \n",
    "        [tok.sep_token_id]\n",
    "    )\n",
    "    print(tok.decode(input_idx))\n",
    "    buffer = input_idx[:]\n",
    "    \n",
    "    for i in range(response_len):\n",
    "        logits = bert(torch.tensor([buffer]))[0]\n",
    "        prediction = getMode(logits)\n",
    "        buffer[len_input + i] = prediction[len_input + i]\n",
    "#         print(i, tok.decode(buffer))\n",
    "    print()\n",
    "    print(tok.decode(buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "077c51fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] nobody expected the cancellation of the flight, so people began to panic. what if the representatives cannot make it in time? [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]? [SEP]\n",
      "\n",
      "[CLS] nobody expected the cancellation of the flight, so people began to panic. what if the representatives cannot make it in time? how long is it going to take? and how long will it take to arrive? [SEP]\n",
      "\n",
      "[CLS] nobody expected the cancellation of the flight, so people began to panic. what if the representatives cannot make it in time? [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]. [SEP]\n",
      "\n",
      "[CLS] nobody expected the cancellation of the flight, so people began to panic. what if the representatives cannot make it in time? \" asked the american. \" yes, \" he replied, \" it will not. [SEP]\n",
      "\n",
      "[CLS] Nobody expected the cancellation of the flight, so people began to panic. What if the representatives cannot make it in time? [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]? [SEP]\n",
      "\n",
      "[CLS] Nobody expected the cancellation of the flight, so people began to panic. What if the representatives cannot make it in time? \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" What? [SEP]\n",
      "\n",
      "[CLS] Nobody expected the cancellation of the flight, so people began to panic. What if the representatives cannot make it in time? [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]. [SEP]\n",
      "\n",
      "[CLS] Nobody expected the cancellation of the flight, so people began to panic. What if the representatives cannot make it in time? \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \". [SEP]\n"
     ]
    }
   ],
   "source": [
    "extend(UNCASED, 16, 'Nobody expected the cancellation of the flight, so people began to panic. What if the representatives cannot make it in time?', '?')\n",
    "print()\n",
    "extend(UNCASED, 16, 'Nobody expected the cancellation of the flight, so people began to panic. What if the representatives cannot make it in time?', '.')\n",
    "print()\n",
    "extend(CASED, 16, 'Nobody expected the cancellation of the flight, so people began to panic. What if the representatives cannot make it in time?', '?')\n",
    "print()\n",
    "extend(CASED, 16, 'Nobody expected the cancellation of the flight, so people began to panic. What if the representatives cannot make it in time?', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a96ee40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]? [SEP]\n",
      "\n",
      "[CLS] \" what the hell are you doing, \" he said, \" getting a gun? [SEP]\n"
     ]
    }
   ],
   "source": [
    "extend(UNCASED, 16, '', '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31a14335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] In reality, my dog [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]. [SEP]\n",
      "\n",
      "[CLS] In reality, my dog is the only - the - best - thing that could ever be in my life. [SEP]\n"
     ]
    }
   ],
   "source": [
    "extend(CASED, 16, 'In reality, my dog', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eefd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def proposeReversal(prompt):\n",
    "#     words = [*reversed(prompt.split(' '))]\n",
    "#     return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82c777fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crab(response_len, prompt, ends_with, sampleMethod, casing, seed=None):\n",
    "    if casing is CASED:\n",
    "        bert = casedBert\n",
    "        tok = casedTok\n",
    "    else:\n",
    "        bert = uncasedBert\n",
    "        tok = uncasedTok\n",
    "    input_idx = tok.encode(prompt.strip(' '))[1:-1]\n",
    "    buffer = [None] * (\n",
    "        1 + len(input_idx) + response_len + len(input_idx) + 1 + 1\n",
    "    )\n",
    "    acc = 0\n",
    "    buffer[acc] = tok.cls_token_id\n",
    "    acc += 1\n",
    "    buffer[acc : acc + len(input_idx)] = input_idx\n",
    "    acc += len(input_idx)\n",
    "    buffer[acc : acc + response_len] = [tok.mask_token_id] * response_len\n",
    "    acc += response_len\n",
    "    buffer[acc : acc + len(input_idx)] = reversed(input_idx)\n",
    "    acc += len(input_idx)\n",
    "    if ends_with:\n",
    "        buffer[acc] = tok.convert_tokens_to_ids(ends_with)\n",
    "        acc += 1\n",
    "    else:\n",
    "        buffer.pop(-1)\n",
    "    buffer[acc] = tok.sep_token_id\n",
    "    acc += 1\n",
    "    assert acc == len(buffer)\n",
    "    \n",
    "    print(tok.decode(buffer))\n",
    "    for i in range((response_len + 1) // 2):\n",
    "#         print(i, tok.decode(buffer))\n",
    "        left  = 1 + len(input_idx) + i\n",
    "        right = 1 + len(input_idx) + response_len - i - 1\n",
    "        if seed is not None:\n",
    "            pick = seed[i]\n",
    "        else:\n",
    "            pick = 0\n",
    "        word_id = sampleMethod(buffer, left, right, pick, bert)\n",
    "        buffer[left] = word_id\n",
    "        buffer[right] = word_id\n",
    "#     print()\n",
    "    print(tok.decode(buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9b64bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastest(buffer, left, right, _, bert):\n",
    "    logits = bert(torch.tensor([buffer]))[0].detach()\n",
    "    logit = (\n",
    "        scipy.special.softmax(logits[0][left]) * \n",
    "        scipy.special.softmax(logits[0][right])\n",
    "    )\n",
    "    return logit.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b727e46f",
   "metadata": {},
   "source": [
    "Optimization: stop looking when left prob < current best shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "32ec85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slowest(buffer, left, right, pick, bert):\n",
    "    logits = bert(torch.tensor([buffer]))[0].detach()\n",
    "    left_probs = scipy.special.softmax(logits[0][left])\n",
    "    left_rank = np.argsort(left_probs)\n",
    "    probs = []\n",
    "    max_prob = [0]\n",
    "    for i, word_id in enumerate(reversed(left_rank)):\n",
    "#         print(i)\n",
    "        left_prob = left_probs[word_id]\n",
    "#         print(left_prob)\n",
    "        if left_prob < max_prob[-1]:\n",
    "            print('  Early stopping at', i, 'which is', i / len(left_probs))\n",
    "            break\n",
    "        buffer[left] = word_id\n",
    "        logits = bert(torch.tensor([buffer]))[0].detach()\n",
    "        right_probs = scipy.special.softmax(logits[0][right])\n",
    "        prob = left_prob * right_probs[word_id]\n",
    "#         print('*', right_probs[word_id], '=', prob)\n",
    "        probs.append((word_id, prob))\n",
    "        max_prob.append(prob)\n",
    "        max_prob.sort(reverse = True)\n",
    "        max_prob = max_prob[:pick + 1]\n",
    "    s = sorted(probs, key=lambda x:x[1])\n",
    "    return s[-1 - pick][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0b37e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAIL_CUT = 0\n",
    "# def slowestRand(buffer, left, right):\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fc0efe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] fall leaves as [MASK] as leaves fall. [SEP]\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "[CLS] fall leaves as soon as leaves fall. [SEP]\n",
      "\n",
      "[CLS] Fall leaves as [MASK] as leaves Fall. [SEP]\n",
      "  Early stopping at 4 which is 0.00013795006207752792\n",
      "[CLS] Fall leaves as easily as leaves Fall. [SEP]\n"
     ]
    }
   ],
   "source": [
    "crab(1, 'Fall leaves as', '.', slowest, UNCASED)\n",
    "print()\n",
    "crab(1, 'Fall leaves as', '.', slowest, CASED, [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7815ff63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] fall leaves [MASK] [MASK] [MASK] leaves fall. [SEP]\n",
      "  Early stopping at 30 which is 0.000982897582071948\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "[CLS] fall leaves falling. falling leaves fall. [SEP]\n"
     ]
    }
   ],
   "source": [
    "crab(3, 'Fall leaves', '.', slowest, UNCASED, [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "11d42836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] fall [MASK] [MASK] [MASK] [MASK] [MASK] fall. [SEP]\n",
      "  Early stopping at 20 which is 0.0006552650547146321\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "[CLS] fall = fall. fall = fall. [SEP]\n"
     ]
    }
   ],
   "source": [
    "crab(5, 'Fall', '.', slowest, UNCASED, [5, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c4d599a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] so patient a nurse [MASK] nurse a patient so. [SEP]\n",
      "  Early stopping at 6 which is 0.00019657951641438963\n",
      "[CLS] so patient a nurse to nurse a patient so. [SEP]\n"
     ]
    }
   ],
   "source": [
    "crab(1, 'So patient a nurse', '.', slowest, UNCASED, [5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7f609e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] so patient a [MASK] [MASK] [MASK] a patient so. [SEP]\n",
      "  Early stopping at 25 which is 0.0008190813183932901\n",
      "  Early stopping at 1 which is 3.2763252735731606e-05\n",
      "[CLS] so patient a doctor a doctor a patient so. [SEP]\n"
     ]
    }
   ],
   "source": [
    "crab(3, 'So patient a', '.', slowest, UNCASED, [2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "751bffc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] is it crazy how saying sentences backwards [MASK] backwards sentences saying how crazy it is? [SEP]\n",
      "  Early stopping at 10 which is 0.00032763252735731603\n",
      "[CLS] is it crazy how saying sentences backwards makes backwards sentences saying how crazy it is? [SEP]\n"
     ]
    }
   ],
   "source": [
    "crab(\n",
    "    1, 'Is it crazy how saying sentences backwards', '?', slowest, \n",
    "    UNCASED, [9], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ac9cef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crab(\n",
    "#     3, 'Is it crazy how saying sentences', '?', slowest, \n",
    "#     UNCASED, [0, 9-9], \n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
