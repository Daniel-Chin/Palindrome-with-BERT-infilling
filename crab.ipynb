{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb5997c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text \n",
    "\n",
    "import tensorflow_hub as hub\n",
    "# import tensorflow_datasets as tfds\n",
    "# tfds.disable_progress_bar()\n",
    "\n",
    "from official.modeling import tf_utils\n",
    "from official import nlp\n",
    "from official.nlp import bert\n",
    "\n",
    "# Load the required submodules\n",
    "import official.nlp.optimization\n",
    "import official.nlp.bert.bert_models\n",
    "import official.nlp.bert.configs\n",
    "import official.nlp.bert.run_classifier\n",
    "import official.nlp.bert.tokenization\n",
    "import official.nlp.data.classifier_data_lib\n",
    "import official.nlp.modeling.losses\n",
    "import official.nlp.modeling.models\n",
    "import official.nlp.modeling.networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa60c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_folder_bert = \"gs://cloud-tpu-checkpoints/bert/v3/uncased_L-12_H-768_A-12\"\n",
    "# tf.io.gfile.listdir(gs_folder_bert)\n",
    "\n",
    "hub_url_bert = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58de1293",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessor = hub.KerasLayer(\n",
    "    'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3', \n",
    ")\n",
    "encoder_inputs = preprocessor(text_input)\n",
    "encoder = hub.KerasLayer(\n",
    "    'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4', \n",
    "    trainable=False, \n",
    ")\n",
    "outputs = encoder(encoder_inputs)\n",
    "pooled_output = outputs[\"pooled_output\"]     # [batch_size, 768].\n",
    "sequence_output = outputs[\"sequence_output\"] # [batch_size, seq_length, 768].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "454b0c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = tf.keras.Model(text_input, pooled_output)\n",
    "sentences = tf.constant([\"Alice used to die a lot\"])\n",
    "# print(embedding_model(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29ab397",
   "metadata": {},
   "source": [
    "## MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f8eb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = hub.load(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n",
    "mlm = hub.KerasLayer(encoder.mlm, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ebae49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = hub.load(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65d76e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 16\n",
    "num_predict = 4\n",
    "\n",
    "mlm_inputs = dict(\n",
    "    input_word_ids=tf.keras.layers.Input(shape=(seq_length,), dtype=tf.int32),\n",
    "    input_mask=tf.keras.layers.Input(shape=(seq_length,), dtype=tf.int32),\n",
    "    input_type_ids=tf.keras.layers.Input(shape=(seq_length,), dtype=tf.int32),\n",
    "    masked_lm_positions=tf.keras.layers.Input(shape=(num_predict,), dtype=tf.int32),\n",
    ")\n",
    "\n",
    "mlm_outputs = mlm(mlm_inputs)\n",
    "mlm_logits = mlm_outputs[\"mlm_logits\"]  # [batch_size, num_predict, vocab_size]\n",
    "# pooled_output = mlm_outputs[\"pooled_output\"]     # [batch_size, 768].\n",
    "# sequence_output = mlm_outputs[\"sequence_output\"] # [batch_size, seq_length, 768].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ab39b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: tokenize batches of text inputs.\n",
    "text_inputs = [\n",
    "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "    *[], \n",
    "] # This SavedModel accepts up to 2 text inputs.\n",
    "tokenize = hub.KerasLayer(preprocessor.tokenize)\n",
    "tokenized_inputs = [tokenize(segment) for segment in text_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5d2ea5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_trackable_child',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_checkpoint_dependencies',\n",
       " '_default_save_signature',\n",
       " '_deferred_dependencies',\n",
       " '_delete_tracking',\n",
       " '_deserialize_from_proto',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_handle_deferred_dependencies',\n",
       " '_is_hub_module_v1',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_map_resources',\n",
       " '_maybe_initialize_trackable',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_no_dependency',\n",
       " '_object_identifier',\n",
       " '_preload_simple_restoration',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_self_name_based_restores',\n",
       " '_self_saveable_object_factories',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_serialize_to_proto',\n",
       " '_setattr_tracking',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_track_trackable',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_update_uid',\n",
       " 'bert_pack_inputs',\n",
       " 'call_and_return_all_conditional_losses',\n",
       " 'graph_debug_info',\n",
       " 'keras_api',\n",
       " 'layer-0',\n",
       " 'layer-1',\n",
       " 'layer-2',\n",
       " 'layer-3',\n",
       " 'regularization_losses',\n",
       " 'signatures',\n",
       " 'tensorflow_git_version',\n",
       " 'tensorflow_version',\n",
       " 'tokenize',\n",
       " 'trainable_variables',\n",
       " 'variables']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0be3266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 (optional): modify tokenized inputs.\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b4e900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: pack input sequences for the Transformer encoder.\n",
    "bert_pack_inputs = hub.KerasLayer(\n",
    "    preprocessor.bert_pack_inputs,\n",
    "    arguments=dict(seq_length=seq_length))  # Optional argument.\n",
    "encoder_inputs = bert_pack_inputs(tokenized_inputs)\n",
    "\n",
    "# mlm_outputs = mlm(encoder_inputs)\n",
    "# mlm_logits = mlm_outputs[\"mlm_logits\"]  # [batch_size, num_predict, vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e4c28ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(text):\n",
    "    prep_model = tf.keras.Model(text_inputs, encoder_inputs)\n",
    "    sentences = tf.constant([\n",
    "        text, \n",
    "    ])\n",
    "    return dict(\n",
    "        **prep_model(sentences), \n",
    "        masked_lm_positions=tf.constant([[3,5,7,9]]), \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54e83e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_mask': <tf.Tensor: shape=(1, 16), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>,\n",
       " 'input_type_ids': <tf.Tensor: shape=(1, 16), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>,\n",
       " 'input_word_ids': <tf.Tensor: shape=(1, 16), dtype=int32, numpy=\n",
       " array([[  101,  7592,  2026, 12043,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0]])>,\n",
       " 'masked_lm_positions': <tf.Tensor: shape=(1, 4), dtype=int32, numpy=array([[3, 5, 7, 9]])>}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep(\"Hello my dude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5884155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-11.770448  -12.12576   -12.188773  ... -10.236775  -11.455725\n",
      "    -7.4752703]\n",
      "  [ -8.606209   -8.841853   -8.818768  ...  -8.891097   -7.7307897\n",
      "    -5.18248  ]\n",
      "  [ -7.917266   -8.057146   -8.08658   ...  -8.0188     -7.3871493\n",
      "    -4.688094 ]\n",
      "  [ -8.401155   -8.482981   -8.588973  ...  -8.461361   -7.946863\n",
      "    -4.342584 ]]], shape=(1, 4, 30522), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mlm_model = tf.keras.Model(mlm_inputs, mlm_logits)\n",
    "sentences = prep(\"Hello my dude\")\n",
    "# sentences = tf.constant(\n",
    "#     prep(\"Hello my dude\"), \n",
    "# )\n",
    "print(mlm_model(sentences))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
